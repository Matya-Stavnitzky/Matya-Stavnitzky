{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RoKGFx_gmEAw",
        "NrKdEr6_eT0R",
        "mIIzR7NLdLCH",
        "OdDUqmOcsWOj"
      ],
      "authorship_tag": "ABX9TyNBR8Ge0LgeHK0JrKuZnGYz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matya-Stavnitzky/Matya-Stavnitzky/blob/main/Cat_Mouse_Reinforcement_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Statements"
      ],
      "metadata": {
        "id": "RoKGFx_gmEAw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dEVOZJ4ttWPG",
        "outputId": "955d770b-ada6-44fa-a263-c47179cdea1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-agents[reverb]\n",
            "  Downloading tf_agents-0.19.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.4.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.2.1)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Collecting gym<=0.23.0,>=0.17.0 (from tf-agents[reverb])\n",
            "  Downloading gym-0.23.0.tar.gz (624 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.25.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (9.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.16.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (3.20.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.14.1)\n",
            "Collecting typing-extensions==4.5.0 (from tf-agents[reverb])\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Collecting pygame==2.1.3 (from tf-agents[reverb])\n",
            "  Downloading pygame-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-probability~=0.23.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.23.0)\n",
            "Collecting rlds (from tf-agents[reverb])\n",
            "  Downloading rlds-0.1.8-py3-none-manylinux2010_x86_64.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dm-reverb~=0.14.0 (from tf-agents[reverb])\n",
            "  Downloading dm_reverb-0.14.0-cp310-cp310-manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.15.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.14.0->tf-agents[reverb]) (0.1.8)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.14.0->tf-agents[reverb]) (1.5.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (24.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (2.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (2.15.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.23.0->tf-agents[reverb]) (4.4.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-agents[reverb]) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.0.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker->dm-reverb~=0.14.0->tf-agents[reverb]) (5.9.5)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.2.2)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.23.0-py3-none-any.whl size=697630 sha256=044ccfca3561dd2b826ce6d31abd17aa56e8891a4ab5ac280be812d27a8ef792\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/6f/b4/3991d4fae11d0ecb0754c11cc1b4e7745012850da4efaaf0b1\n",
            "Successfully built gym\n",
            "Installing collected packages: typing-extensions, rlds, pygame, gym, tf-agents, dm-reverb\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.5.2\n",
            "    Uninstalling pygame-2.5.2:\n",
            "      Successfully uninstalled pygame-2.5.2\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.0+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "sqlalchemy 2.0.30 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic 2.7.3 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.18.4 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "torch 2.3.0+cu121 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dm-reverb-0.14.0 gym-0.23.0 pygame-2.1.3 rlds-0.1.8 tf-agents-0.19.0 typing-extensions-4.5.0\n",
            "Requirement already satisfied: tf-keras in /usr/local/lib/python3.10/dist-packages (2.15.1)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tf-keras) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15->tf-keras) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tf-agents[reverb]\n",
        "!pip install tf-keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Keep using keras-2 (tf-keras) rather than keras-3 (keras).\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
      ],
      "metadata": {
        "id": "tiKWwSw7mLWL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import abc\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from tf_agents.environments import py_environment\n",
        "from tf_agents.environments import tf_environment\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.environments import utils\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.environments import wrappers\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.trajectories import time_step as ts"
      ],
      "metadata": {
        "id": "g5CoIC_AmXqu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#WORKING ENVIRONMENT"
      ],
      "metadata": {
        "id": "NrKdEr6_eT0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CardGameEnv(py_environment.PyEnvironment):\n",
        "\n",
        "  number_steps_index = 0\n",
        "  mouse_index = 1\n",
        "  cat_index = 2\n",
        "\n",
        "  def __init__(self):\n",
        "    self._action_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(2,), dtype=np.int32, minimum=[0,0], maximum=[1,1], name='action')\n",
        "    self._observation_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(1,3), dtype=np.float32, minimum=0, name='observation')\n",
        "\n",
        "    self._state = [0, 2, 4]\n",
        "    self._episode_ended = False\n",
        "\n",
        "  def action_spec(self):\n",
        "    return self._action_spec\n",
        "\n",
        "  def observation_spec(self):\n",
        "    return self._observation_spec\n",
        "\n",
        "  def _reset(self):\n",
        "    self._state = [0, 2, 4]\n",
        "    self._episode_ended = False\n",
        "    return ts.restart(np.array([self._state], dtype=np.float32))\n",
        "\n",
        "\n",
        "  def _step(self, action):\n",
        "\n",
        "    if self._episode_ended:\n",
        "      # The last action ended the episode. Ignore the current action and start\n",
        "      # a new episode.\n",
        "      return self.reset()\n",
        "\n",
        "    # check action\n",
        "    #print('Action: ', action)\n",
        "    #print('State before: ', self._state)\n",
        "    cost_tally = [0, 0]\n",
        "    if action[0] == 0: #if mouse\n",
        "      if action[1] == 1: #if close\n",
        "        cost_tally[0] -= 2\n",
        "      else:\n",
        "        #move the mouse\n",
        "        mouse_location = self._state[self.mouse_index]\n",
        "        if mouse_location == 1:\n",
        "            self._state[self.mouse_index] = 3\n",
        "        elif mouse_location == 2:\n",
        "            self._state[self.mouse_index] = 1\n",
        "        else:\n",
        "            self._state[self.mouse_index] = 2\n",
        "\n",
        "        cost_tally[0] += 1\n",
        "        if self._state[self.mouse_index] == 3: #if mouse in room 3\n",
        "          cost_tally[1] += 1\n",
        "    else:\n",
        "      if action[1] == 1: #if close\n",
        "        cost_tally[1] -= 2\n",
        "      else:\n",
        "        #move the cat\n",
        "        cat_location = self._state[self.cat_index]\n",
        "        #print(f\"cat starting location {cat_location}\")\n",
        "        if cat_location == 3:\n",
        "            self._state[self.cat_index] = 4\n",
        "        elif cat_location == 4:\n",
        "            self._state[self.cat_index] = 5\n",
        "        else:\n",
        "            self._state[self.cat_index] = 3\n",
        "        #print(f\"cat ending location {self._state[self.cat_index]}\")\n",
        "\n",
        "        cost_tally[1] += 1\n",
        "        if self._state[self.cat_index] == 3: #if cat in room 3\n",
        "          cost_tally[0] += 1\n",
        "    #print('Action data type: ', type(action))\n",
        "\n",
        "\n",
        "    # calc state\n",
        "    if self._state[self.mouse_index] == self._state[self.cat_index]:\n",
        "      #print(f\"cat and mouse met, state {self._state}\")\n",
        "      self._episode_ended = True\n",
        "    self._state[0] += 1\n",
        "    #print('State after: ', self._state)\n",
        "\n",
        "\n",
        "    if self._episode_ended:\n",
        "      reward = -10\n",
        "      return ts.termination(np.array([self._state],  dtype=np.float32), reward)\n",
        "    elif self._state[0] > 100:\n",
        "      return ts.termination(np.array([self._state],  dtype=np.float32), 0)\n",
        "    else:\n",
        "      reward = cost_tally[action[0]] + np.random.normal(0, 0.1) #ADD RANDOM NOISE TO REWARD AS SPECIFIED BY PAPER\n",
        "      return ts.transition(\n",
        "          np.array([self._state], dtype=np.float32), reward=reward, discount=1.0)"
      ],
      "metadata": {
        "id": "bkm_laxwwANF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "environment = CardGameEnv()\n",
        "utils.validate_py_environment(environment, episodes=5)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RrFsGPFZfWHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac8e3a7-ddbc-4d0a-994a-78751eba811b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tf_agents/specs/array_spec.py:352: RuntimeWarning: invalid value encountered in cast\n",
            "  self._minimum[self._minimum == -np.inf] = low\n",
            "/usr/local/lib/python3.10/dist-packages/tf_agents/specs/array_spec.py:353: RuntimeWarning: invalid value encountered in cast\n",
            "  self._minimum[self._minimum == np.inf] = high\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Supervisors (AGENTS)"
      ],
      "metadata": {
        "id": "mIIzR7NLdLCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def epsilon_greedy_policy(Qtable, state, epsilon):\n",
        "  random_int = random.uniform(0,1)\n",
        "  if random_int > epsilon:\n",
        "    action = np.argmax(Qtable[state])\n",
        "  else:\n",
        "    action = random.choice([0, 1])\n",
        "  return action"
      ],
      "metadata": {
        "id": "joCrFu23wVso"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#epsilon_greedy_policy test\n"
      ],
      "metadata": {
        "id": "rSlZgM32X7jr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#helper functions"
      ],
      "metadata": {
        "id": "_dP_463F-7n3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "33\n",
        "34\n",
        "35\n",
        "-13\n",
        "-14\n",
        "-15\n",
        "\"\"\"\n",
        "def state_conversion_cat(state):\n",
        "  if state[1] == 3:\n",
        "    return int(state[2]-3)\n",
        "  else:\n",
        "    return int(state[2])"
      ],
      "metadata": {
        "id": "0oZ0d4OZ1gLz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test for state_conversion_cat\n",
        "print(state_conversion_cat([0, 3, 3]))\n",
        "print(state_conversion_cat([0, 3, 4]))\n",
        "print(state_conversion_cat([0, 3, 5]))\n",
        "print(state_conversion_cat([0, 1, 3]))\n",
        "print(state_conversion_cat([0, 1, 4]))\n",
        "print(state_conversion_cat([0, 1, 5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWfTAZGsUq2D",
        "outputId": "57189103-05f8-4c75-e1db-7b4389d8ab3f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_q_table(state_space, action_space):\n",
        "  Qtable = np.zeros((state_space, action_space))\n",
        "  return Qtable"
      ],
      "metadata": {
        "id": "5fwHtyOr3i0A"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test for inirialize_q_table\n",
        "print(initialize_q_table(2, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WQo0KoDVZml",
        "outputId": "d1252611-508a-44aa-8f31-4ad72745b250"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "13\n",
        "23\n",
        "33\n",
        "1-1\n",
        "2-1\n",
        "3-1\n",
        "\"\"\"\n",
        "def state_conversion_mouse(state):\n",
        "  if state[2] == 3:\n",
        "    return int(state[1]-1)\n",
        "  else:\n",
        "    return int(state[1]+2)"
      ],
      "metadata": {
        "id": "82UjUx8F2yRh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test for start_conversion_mouse\n",
        "print(state_conversion_mouse([0, 1, 3]))\n",
        "print(state_conversion_mouse([0, 2, 3]))\n",
        "print(state_conversion_mouse([0, 3, 3]))\n",
        "print(state_conversion_mouse([0, 1, 4]))\n",
        "print(state_conversion_mouse([0, 2, 4]))\n",
        "print(state_conversion_mouse([0, 3, 5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkeSVPUBVlDZ",
        "outputId": "4b9c7806-cc9c-4cb6-960f-a0f238f12700"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_table(Qtable, state, action, learning_rate, reward, gamma, new_state):\n",
        "  Qtable[state][action] = Qtable[state][action] + learning_rate * (reward + gamma * np.max(Qtable[new_state]) - Qtable[state][action])"
      ],
      "metadata": {
        "id": "jxyyWVqy7Fu0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test for update_table\n",
        "mouse_q = initialize_q_table(6, 2)\n",
        "cat_q = initialize_q_table(6, 2)\n",
        "#start state [0, 2, 4]\n",
        "start_state_m = state_conversion_mouse([0, 2, 4])\n",
        "#mouse move action 0\n",
        "#next state [1, 3, 4]\n",
        "end_state_m = state_conversion_mouse([1, 3, 4])\n",
        "#updating table\n",
        "update_table(mouse_q, start_state_m, 0, 0.1, -10, 0.9, end_state_m)\n",
        "print(mouse_q)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps6Rl1n9V289",
        "outputId": "a993a853-d2be-43c8-9026-f46e7f801273"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  0.]\n",
            " [ 0.  0.]\n",
            " [ 0.  0.]\n",
            " [ 0.  0.]\n",
            " [-1.  0.]\n",
            " [ 0.  0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Loop"
      ],
      "metadata": {
        "id": "OdDUqmOcsWOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(n_training_episodes, epsilon, alpha, gamma, env, max_steps, mouse_S, cat_S):\n",
        "  for episode in range(n_training_episodes):\n",
        "\n",
        "    # Reset the environment\n",
        "    info, reward, done, state = env.reset()\n",
        "    state = state[0]\n",
        "    cat_state = state_conversion_cat(state)\n",
        "    mouse_state = state_conversion_mouse(state)\n",
        "    #step = 0\n",
        "    done = False\n",
        "\n",
        "    # repeat\n",
        "    for step in range(max_steps):\n",
        "\n",
        "      #decide if moving cat or mouse 0 = mouse\n",
        "      move = random.choice([0, 1])\n",
        "      if move == 0:\n",
        "        action = epsilon_greedy_policy(mouse_S, mouse_state, epsilon)\n",
        "      else:\n",
        "        action = epsilon_greedy_policy(cat_S, cat_state, epsilon)\n",
        "\n",
        "\n",
        "      info, reward, done, new_state = env.step([move, action])\n",
        "      new_state = new_state[0] #CHECK THIS\n",
        "      new_cat_state = state_conversion_cat(new_state)\n",
        "      new_mouse_state = state_conversion_mouse(new_state)\n",
        "\n",
        "      #print(f\"starting state {state}, new_state {new_state}\")\n",
        "      #print(f\"move made: {move} {action}\")\n",
        "\n",
        "\n",
        "      #update policy (need to go through equations to make sure it's accurate)\n",
        "      if reward == -10: #need to check this NEGATIVE IMPACT FOR BOTH\n",
        "          update_table(mouse_S, mouse_state, action, alpha, reward, gamma, new_mouse_state)  #update mouse\n",
        "          update_table(cat_S, cat_state, action, alpha, reward, gamma, new_cat_state)  #update cat\n",
        "      else:\n",
        "        if move == 0:\n",
        "          update_table(mouse_S, mouse_state, action, alpha, reward, gamma, new_mouse_state)  #update mouse\n",
        "          if action == 0 and state[1] == 3: #are you supposed to update if reward == 0 IS THERE NOISE HERE\n",
        "            update_table(cat_S, cat_state, action, alpha, 1, gamma, new_cat_state)\n",
        "          else:\n",
        "            update_table(cat_S, cat_state, action, alpha, 0, gamma, new_cat_state)\n",
        "        else:\n",
        "          update_table(cat_S, cat_state, action, alpha, reward, gamma, new_cat_state)  #update cat\n",
        "          if action == 0 and state[2] == 3:\n",
        "            update_table(mouse_S, mouse_state, action, alpha, 1, gamma, new_mouse_state)\n",
        "          else:\n",
        "            update_table(mouse_S, mouse_state, action, alpha, 0, gamma, new_mouse_state)\n",
        "\n",
        "\n",
        "      # If done, finish the episode\n",
        "      if not done:\n",
        "        #print(f\"finished episode, end state {new_state}\")\n",
        "        break\n",
        "\n",
        "      # Our state is the new state\n",
        "      state = new_state\n",
        "      mouse_state = new_mouse_state\n",
        "      cat_state = new_cat_state\n",
        "\n",
        "  return [mouse_S, cat_S]"
      ],
      "metadata": {
        "id": "PugbhhOsh1iu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "alpha = 0.1\n",
        "gamma = 0.9\n",
        "epsilon = 0.1\n",
        "n_training_episodes = 10000\n",
        "learning_rate = 0.1  #alpha\n",
        "\n",
        "# Evaluation parameters\n",
        "n_eval_episodes = 100\n",
        "\n",
        "#environment\n",
        "env = CardGameEnv()\n",
        "\n",
        "#Q-tables\n",
        "state_space = 6\n",
        "action_space = 2\n",
        "mouse_Qtable = initialize_q_table(state_space, action_space)\n",
        "cat_Qtable = initialize_q_table(state_space, action_space)"
      ],
      "metadata": {
        "id": "jfLfpcDndNHw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(n_training_episodes, epsilon , alpha, gamma, env, 20,  mouse_Qtable, cat_Qtable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qgk8yLr6_oSR",
        "outputId": "7aee68de-7e34-4ffd-b6ba-0e82ee485ca4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-7.91939728, -7.71958462],\n",
              "        [-3.03585736, -4.20119749],\n",
              "        [ 0.        ,  0.        ],\n",
              "        [-4.46299243, -5.3976775 ],\n",
              "        [-2.50724767, -2.6687002 ],\n",
              "        [-3.74303345, -6.02966528]]),\n",
              " array([[ 0.        ,  0.        ],\n",
              "        [-3.59845072, -4.29039113],\n",
              "        [-5.77987454, -7.4544766 ],\n",
              "        [-6.53365453, -6.72981021],\n",
              "        [-2.45649251, -3.81941557],\n",
              "        [-3.65250094, -5.37488878]])]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ONE TEST: POLICY FORMED\n",
        "\n",
        "Mouse\n",
        "\n",
        "-6.10693584, -5.0698584\n",
        "\n",
        "-2.33158313, -2.278446\n",
        "\n",
        "0        ,  0.       \n",
        "\n",
        "4.11305957,  3.6347789\n",
        "  \n",
        "4.60095968,  4.04064418\n",
        "\n",
        "3.97011286,  3.10334809\n",
        "\n",
        "\n",
        "CAT\n",
        "\n",
        "0        , 0.       \n",
        "\n",
        "8.58297923, 7.96147233\n",
        "\n",
        "8.05288662, 7.98932263\n",
        "\n",
        "3.32721638, 5.1754332\n",
        "\n",
        "8.29258907, 9.12580202\n",
        "\n",
        "8.10549219, 9.80908741"
      ],
      "metadata": {
        "id": "RPd-HuEhmYuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#edited Training loop (to fix?)"
      ],
      "metadata": {
        "id": "GMXKjMW7UkG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CardGameEnvEdited(py_environment.PyEnvironment):\n",
        "\n",
        "  number_steps_index = 0\n",
        "  mouse_index = 1\n",
        "  cat_index = 2\n",
        "  move_reward = 1\n",
        "  end_punishment = -10\n",
        "  stop_punishment = 0\n",
        "\n",
        "  def __init__(self):\n",
        "    self._action_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(2,), dtype=np.int32, minimum=[0,0], maximum=[1,1], name='action')\n",
        "    self._observation_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(1,3), dtype=np.float32, minimum=0, name='observation')\n",
        "\n",
        "    self._state = [0, 2, 4]\n",
        "    self._episode_ended = False\n",
        "\n",
        "  def action_spec(self):\n",
        "    return self._action_spec\n",
        "\n",
        "  def observation_spec(self):\n",
        "    return self._observation_spec\n",
        "\n",
        "  def _reset(self):\n",
        "    self._state = [0, 2, 4]\n",
        "    self._episode_ended = False\n",
        "    return ts.restart(np.array([self._state], dtype=np.float32))\n",
        "\n",
        "\n",
        "  def _step(self, action):\n",
        "\n",
        "    if self._episode_ended:\n",
        "      # The last action ended the episode. Ignore the current action and start\n",
        "      # a new episode.\n",
        "      return self.reset()\n",
        "\n",
        "    # check action\n",
        "    #print('Action: ', action)\n",
        "    #print('State before: ', self._state)\n",
        "    cost_tally = [0, 0]\n",
        "    if action[0] == 0: #if mouse\n",
        "      if action[1] == 1: #if close\n",
        "        cost_tally[0] -= self.stop_punishment\n",
        "      else:\n",
        "        #move the mouse\n",
        "        mouse_location = self._state[self.mouse_index]\n",
        "        if mouse_location == 1:\n",
        "            self._state[self.mouse_index] = 3\n",
        "        elif mouse_location == 2:\n",
        "            self._state[self.mouse_index] = 1\n",
        "        else:\n",
        "            self._state[self.mouse_index] = 2\n",
        "\n",
        "        cost_tally[0] += self.move_reward\n",
        "        if self._state[self.mouse_index] == 3: #if mouse in room 3\n",
        "          cost_tally[1] += self.move_reward\n",
        "    else:\n",
        "      if action[1] == 1: #if close\n",
        "        cost_tally[1] -= self.stop_punishment\n",
        "      else:\n",
        "        #move the cat\n",
        "        cat_location = self._state[self.cat_index]\n",
        "        #print(f\"cat starting location {cat_location}\")\n",
        "        if cat_location == 3:\n",
        "            self._state[self.cat_index] = 4\n",
        "        elif cat_location == 4:\n",
        "            self._state[self.cat_index] = 5\n",
        "        else:\n",
        "            self._state[self.cat_index] = 3\n",
        "        #print(f\"cat ending location {self._state[self.cat_index]}\")\n",
        "\n",
        "        cost_tally[1] += self.move_reward\n",
        "        if self._state[self.cat_index] == 3: #if cat in room 3\n",
        "          cost_tally[0] += self.move_reward\n",
        "    #print('Action data type: ', type(action))\n",
        "\n",
        "\n",
        "    # calc state\n",
        "    if self._state[self.mouse_index] == self._state[self.cat_index]:\n",
        "      #print(f\"cat and mouse met, state {self._state}\")\n",
        "      self._episode_ended = True\n",
        "    self._state[0] += 1\n",
        "    #print('State after: ', self._state)\n",
        "\n",
        "\n",
        "    if self._episode_ended:\n",
        "      reward = self.end_punishment\n",
        "      return ts.termination(np.array([self._state],  dtype=np.float32), reward)\n",
        "    elif self._state[0] > 20:\n",
        "      return ts.termination(np.array([self._state],  dtype=np.float32), 0)\n",
        "    else:\n",
        "      reward = cost_tally[action[0]] + np.random.normal(0, 0.1) #ADD RANDOM NOISE TO REWARD AS SPECIFIED BY PAPER\n",
        "      return ts.transition(\n",
        "          np.array([self._state], dtype=np.float32), reward=reward, discount=1.0)"
      ],
      "metadata": {
        "id": "NmJWuGkiwhAI"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(n_training_episodes, epsilon, alpha, gamma, env, max_steps, mouse_S, cat_S):\n",
        "  for episode in range(n_training_episodes):\n",
        "\n",
        "    # Reset the environment\n",
        "    info, reward, done, state = env.reset()\n",
        "    state = state[0]\n",
        "    cat_state = state_conversion_cat(state)\n",
        "    mouse_state = state_conversion_mouse(state)\n",
        "\n",
        "\n",
        "    # repeat\n",
        "    for step in range(max_steps):\n",
        "\n",
        "      #decide if moving cat or mouse 0 = mouse\n",
        "      move = random.choice([0, 1])\n",
        "      if move == 0:\n",
        "        action = epsilon_greedy_policy(mouse_S, mouse_state, epsilon)\n",
        "      else:\n",
        "        action = epsilon_greedy_policy(cat_S, cat_state, epsilon)\n",
        "\n",
        "\n",
        "      info, reward, done, new_state = env.step([move, action])\n",
        "      new_state = new_state[0] #CHECK THIS\n",
        "      new_cat_state = state_conversion_cat(new_state)\n",
        "      new_mouse_state = state_conversion_mouse(new_state)\n",
        "\n",
        "      #print(f\"starting state {state}, new_state {new_state}\")\n",
        "      #print(f\"move made: {move} {action}\")\n",
        "\n",
        "\n",
        "      #update policy (need to go through equations to make sure it's accurate)\n",
        "      if move == 0:\n",
        "        update_table(mouse_S, mouse_state, action, alpha, reward, gamma, new_mouse_state)  #update mouse\n",
        "      else:\n",
        "        update_table(cat_S, cat_state, action, alpha, reward, gamma, new_cat_state)  #update cat\n",
        "\n",
        "      # If done, finish the episode\n",
        "      if not done:\n",
        "        #print(f\"finished episode, end state {new_state}\")\n",
        "        break\n",
        "\n",
        "      # Our state is the new state\n",
        "      state = new_state\n",
        "      mouse_state = new_mouse_state\n",
        "      cat_state = new_cat_state\n",
        "\n",
        "  return [mouse_S, cat_S]"
      ],
      "metadata": {
        "id": "U2CZLgwlUnAU"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "alpha = 0.1\n",
        "gamma = 0.9\n",
        "epsilon = 0.1\n",
        "n_training_episodes = 10000\n",
        "learning_rate = 0.1  #alpha\n",
        "\n",
        "# Evaluation parameters\n",
        "n_eval_episodes = 100\n",
        "\n",
        "#environment\n",
        "env = CardGameEnvEdited()\n",
        "\n",
        "#Q-tables\n",
        "state_space = 6\n",
        "action_space = 2\n",
        "mouse_Qtable = initialize_q_table(state_space, action_space)\n",
        "cat_Qtable = initialize_q_table(state_space, action_space)"
      ],
      "metadata": {
        "id": "5Fp7iRZAUqUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a2183e0-7f14-48b8-d0af-ebe1d4e939c3"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tf_agents/specs/array_spec.py:352: RuntimeWarning: invalid value encountered in cast\n",
            "  self._minimum[self._minimum == -np.inf] = low\n",
            "/usr/local/lib/python3.10/dist-packages/tf_agents/specs/array_spec.py:353: RuntimeWarning: invalid value encountered in cast\n",
            "  self._minimum[self._minimum == np.inf] = high\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(arr):\n",
        "  out = []\n",
        "  for i in range(len(arr)):\n",
        "    if arr[i][0] > arr[i][1]:\n",
        "      out.append(\"move\")\n",
        "    else:\n",
        "      out.append(\"stop\")\n",
        "  return out"
      ],
      "metadata": {
        "id": "L86GX1INooHK"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_clear(m, c):\n",
        "  mm = [\"13\", \"23\", \"33\", \"1?\", \"2?\", \"3?\"]\n",
        "  cc = [\"33\", \"34\", \"35\", \"?3\", \"?4\", \"?5\"]\n",
        "  print(\"MOUSE\")\n",
        "  for i in range(len(m)):\n",
        "    print(f\"{mm[i]} {m[i]}\")\n",
        "\n",
        "  print(\"CAT\")\n",
        "  for i in range(len(m)):\n",
        "    print(f\"{cc[i]} {c[i]}\")"
      ],
      "metadata": {
        "id": "rZhiHf-mqqq7"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mouse, cat = train(n_training_episodes, epsilon , alpha, gamma, env, 20,  mouse_Qtable, cat_Qtable)\n",
        "print(mouse)\n",
        "print(cat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGWv1VeJUr6O",
        "outputId": "25722870-68b2-4ac7-b539-e8d4fc810d06"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-10.           0.10155894]\n",
            " [  1.10168522   0.91609397]\n",
            " [  0.           0.        ]\n",
            " [  9.96877845   9.01483316]\n",
            " [  9.97530568   8.97543512]\n",
            " [  9.97069427   8.99649132]]\n",
            "[[  0.           0.        ]\n",
            " [  1.04882979   0.87487941]\n",
            " [-10.           0.01381633]\n",
            " [ 10.05632259   9.06499858]\n",
            " [ 10.03458288   9.01096959]\n",
            " [ 10.09192254   9.03855527]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_clear(convert(mouse), convert(cat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u1LcczAs0zh",
        "outputId": "6f05bc7f-c938-4800-c5d1-f8a1babe768d"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MOUSE\n",
            "13 stop\n",
            "23 move\n",
            "33 stop\n",
            "1? move\n",
            "2? move\n",
            "3? move\n",
            "CAT\n",
            "33 stop\n",
            "34 move\n",
            "35 stop\n",
            "?3 move\n",
            "?4 move\n",
            "?5 move\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cat_junk(start_state, end_state):\n",
        "  cat_state = state_conversion_cat(start_state)\n",
        "  new_cat_state = state_conversion_cat(end_state)\n",
        "  update_table(cat_q, cat_state, 0, alpha, reward, gamma, new_cat_state)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "yB9SbxjLs7oO"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mouse_junk(start_state, end_state):\n",
        "  mouse_state = state_conversion_mouse(start_state)\n",
        "  new_mouse_state = state_conversion_mouse(end_state)\n",
        "  update_table(mouse_q, mouse_state, 0, alpha, reward, gamma, new_mouse_state)"
      ],
      "metadata": {
        "id": "tSPTo9ELu-m5"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mouse_q = initialize_q_table(6, 2)\n",
        "cat_q = initialize_q_table(6, 2)\n",
        "info, reward, done, state = env.reset()\n",
        "info, reward, done, state2 = env.step([1,0])\n",
        "print(reward)\n",
        "cat_junk(state[0], state2[0])\n",
        "print(cat_q)\n",
        "info, reward, done, state3 = env.step([1,0])\n",
        "cat_junk(state2[0], state3[0])\n",
        "print(cat_q)\n",
        "print(reward)\n",
        "info, reward, done, state4 = env.step([0,0])\n",
        "mouse_junk(state3[0], state4[0])\n",
        "print(mouse_q)\n",
        "info, reward, done, state5 = env.step([0,0])\n",
        "mouse_junk(state4[0], state5[0])\n",
        "print(state5)\n",
        "print(mouse_q)\n",
        "print(reward)\n",
        "print(done)\n",
        "info, reward, done, state6 = env.step([0,0])\n",
        "print(done)\n",
        "print(reward)\n",
        "print(state6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1LOG6uDsv17",
        "outputId": "75d66780-142f-4319-a6a0-d4f5d3c9e779"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8005183\n",
            "[[0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.08005183 0.        ]\n",
            " [0.         0.        ]]\n",
            "[[0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.08005183 0.        ]\n",
            " [0.10751667 0.        ]]\n",
            "1.0751667\n",
            "[[0.         0.        ]\n",
            " [0.10726993 0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]\n",
            " [0.         0.        ]]\n",
            "[[4. 3. 3.]]\n",
            "[[-1.          0.        ]\n",
            " [ 0.10726993  0.        ]\n",
            " [ 0.          0.        ]\n",
            " [ 0.          0.        ]\n",
            " [ 0.          0.        ]\n",
            " [ 0.          0.        ]]\n",
            "-10.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "[[0. 2. 4.]]\n"
          ]
        }
      ]
    }
  ]
}